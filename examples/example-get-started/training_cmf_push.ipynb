{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08452986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "import numpy as np\n",
    "from cmflib import cmf\n",
    "from cmflib.cmf import metadata_push, artifact_push\n",
    "import os\n",
    "import io\n",
    "import re \n",
    "import sys\n",
    "import yaml\n",
    "import gzip\n",
    "import pickle\n",
    "import random\n",
    "import typing as t\n",
    "import collections\n",
    "import click\n",
    "import xml.etree.ElementTree\n",
    "from cmflib import cmfquery\n",
    "from cmflib.cli.utils import find_root\n",
    "from cmflib.utils.cmf_config import CmfConfig\n",
    "import requests\n",
    "from sklearn.feature_extraction.text import (CountVectorizer, TfidfTransformer)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import json\n",
    "import math\n",
    "import sklearn.metrics as metrics\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3527a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote.local-storage.url=/home/user/local-storage\n",
      "core.remote=local-storage\n",
      "cmf-server-url = http://localhost:80\n"
     ]
    }
   ],
   "source": [
    "#CHECK WHETHER CMF IS INITIALIZED\n",
    "_=cmf.cmf_init_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fb8336e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cmf init.\n",
      "Setting 'local-storage' as a default remote.\n",
      "cmf init complete.\n"
     ]
    }
   ],
   "source": [
    "#INITIALIZING LOCAL REPOSITORY\n",
    "init=cmf.cmf_init(type=\"local\",path=\"/home/user/local-storage\",git_remote_url=\"http://github.com\",cmf_server_url=\"http://localhost:80\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19269894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Note: CMF will check out a new branch in git to commit the metadata files ***\n",
      "*** The checked out branch is mlmd. ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\u280b Checking graph graph\n",
      "\\u280b Checking graph graph\n",
      "\\u2839 Checking graph graph\n",
      "\u001b[?25h\r"
     ]
    }
   ],
   "source": [
    "__all__ = ['parse']\n",
    "def _process_posts(fd_in: t.IO, fd_out_train: t.IO, fd_out_test: t.IO, target_tag: str, split: int) -> None:\n",
    "    for idx, line in enumerate(fd_in):\n",
    "        try:\n",
    "            fd_out = fd_out_train if random.random() > split else fd_out_test\n",
    "            attr = xml.etree.ElementTree.fromstring(line).attrib\n",
    "\n",
    "            pid = attr.get(\"Id\", \"\")\n",
    "            label = 1 if target_tag in attr.get(\"Tags\", \"\") else 0\n",
    "            title = re.sub(r\"\\s+\", \" \", attr.get(\"Title\", \"\")).strip()\n",
    "            body = re.sub(r\"\\s+\", \" \", attr.get(\"Body\", \"\")).strip()\n",
    "            text = title + \" \" + body\n",
    "\n",
    "            fd_out.write(\"{}\\t{}\\t{}\\n\".format(pid, label, text))\n",
    "        except Exception as ex:\n",
    "            sys.stderr.write(f\"Skipping the broken line {idx}: {ex}\\n\")\n",
    "def parse(input_file: str, output_dir: str) -> None:\n",
    "    \"\"\" Parse input file (input_file) and create train/test files in output_dir directory.\n",
    "    Args:\n",
    "         input_file: Path to a compressed (.gz) XML-lines file (data.xml.gz).\n",
    "         output_dir: Path to a directory that will contain train (train.tsv) and test (test.tsv) files.\n",
    "\n",
    "    Machine Learning Artifacts:\n",
    "        Input: ${input_file}\n",
    "        Output: ${output_dir}/train.tsv, ${output_dir}/test.tsv\n",
    "    \"\"\"\n",
    "    params = yaml.safe_load(open(\"params.yaml\"))[\"parse\"]\n",
    "    random.seed(params[\"seed\"])\n",
    "    graph_env = os.getenv(\"NEO4J\", \"False\")\n",
    "    graph = True if graph_env == \"True\" or graph_env == \"TRUE\" else False\n",
    "    metawriter = cmf.Cmf(filename=\"mlmd\", pipeline_name=\"Test-env\", graph=graph)\n",
    "    _ = metawriter.create_context(pipeline_stage=\"Prepare\", custom_properties={\"user-metadata1\": \"metadata_value\"})\n",
    "    _ = metawriter.create_execution(execution_type=\"Prepare\", custom_properties=params)\n",
    "    _ = metawriter.log_dataset(input_file, \"input\", custom_properties={\"user-metadata1\": \"metadata_value\"})\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    Dataset = collections.namedtuple('Dataset', ['train', 'test'])\n",
    "    output_ds = Dataset(train=os.path.join(output_dir, \"train.tsv\"), test=os.path.join(output_dir, \"test.tsv\"))\n",
    "\n",
    "    with gzip.open(input_file, \"rb\") as fd_in,\\\n",
    "         io.open(output_ds.train, \"w\", encoding=\"utf8\") as fd_out_train,\\\n",
    "         io.open(output_ds.test, \"w\", encoding=\"utf8\") as fd_out_test:\n",
    "        _process_posts(fd_in, fd_out_train, fd_out_test, \"<python>\", params[\"split\"])\n",
    "\n",
    "    _ = metawriter.log_dataset(output_ds.train, \"output\")\n",
    "    _ = metawriter.log_dataset(output_ds.test, \"output\")\n",
    "\n",
    "\n",
    "def parse_cli(input_file: str, output_dir: str) -> None:\n",
    "    parse(input_file, output_dir)\n",
    "\n",
    "parse_cli(\"artifacts/data.xml.gz\", \"artifacts/parsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f1d9a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Note: CMF will check out a new branch in git to commit the metadata files ***\n",
      "*** The checked out branch is mlmd. ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\u2819 Checking graph graph\n",
      "\\u280b Checking graph graph\n",
      "The input data frame artifacts/parsed/train.tsv size is (20017, 3)\n",
      "The output matrix artifacts/features/train.pkl size is (20017, 3002) and data type is float64\n",
      "The input data frame artifacts/parsed/test.tsv size is (4983, 3)\n",
      "The output matrix artifacts/features/test.pkl size is (4983, 3002) and data type is float64\n",
      "\\u2819 Checking graph graph\n",
      "\\u2819 Checking graph graph\n",
      "\u001b[?25h\r"
     ]
    }
   ],
   "source": [
    "__all__ = ['featurize']\n",
    "def _get_df(data: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(\n",
    "        data,\n",
    "        encoding=\"utf-8\",\n",
    "        header=None,\n",
    "        delimiter=\"\\t\",\n",
    "        names=[\"id\", \"label\", \"text\"],\n",
    "    )\n",
    "    sys.stderr.write(f\"The input data frame {data} size is {df.shape}\\n\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def _save_matrix(df: pd.DataFrame, matrix, output: str) -> None:\n",
    "    id_matrix = sparse.csr_matrix(df.id.astype(np.int64)).T\n",
    "    label_matrix = sparse.csr_matrix(df.label.astype(np.int64)).T\n",
    "\n",
    "    result = sparse.hstack([id_matrix, label_matrix, matrix], format=\"csr\")\n",
    "\n",
    "    msg = \"The output matrix {} size is {} and data type is {}\\n\"\n",
    "    sys.stderr.write(msg.format(output, result.shape, result.dtype))\n",
    "\n",
    "    with open(output, \"wb\") as fd:\n",
    "        pickle.dump(result, fd)\n",
    "\n",
    "def featurize(input_dir: str, output_dir: str) -> None:\n",
    "    \"\"\" Create train and test Machine Learning datasets.\n",
    "    Args:\n",
    "        input_dir: Path to a directory containing train.tsv and test.tsv files.\n",
    "        output_dir: Path to a directory that will contain train.pkl and test.pkl files.\n",
    "\n",
    "    Machine Learning Artifacts:\n",
    "        Input: ${input_dir}/train.tsv, ${input_dir}/test.tsv\n",
    "        Output: ${output_dir}/train.pkl, ${output_dir}/test.pkl\n",
    "    \"\"\"\n",
    "    params = yaml.safe_load(open(\"params.yaml\"))[\"featurize\"]\n",
    "    np.set_printoptions(suppress=True)\n",
    "\n",
    "    Dataset = collections.namedtuple('Dataset', ['train', 'test'])\n",
    "    input_ds = Dataset(train=os.path.join(input_dir, \"train.tsv\"), test=os.path.join(input_dir, \"test.tsv\"))\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_ds = Dataset(train=os.path.join(output_dir, \"train.pkl\"), test=os.path.join(output_dir, \"test.pkl\"))\n",
    "    graph_env = os.getenv(\"NEO4J\", \"False\")\n",
    "    graph = True if graph_env == \"True\" or graph_env == \"TRUE\" else False\n",
    "    metawriter = cmf.Cmf(filename=\"mlmd\", pipeline_name=\"Test-env\", graph=graph)\n",
    "\n",
    "    _ = metawriter.create_context(pipeline_stage=\"Featurize\")\n",
    "    _ = metawriter.create_execution(execution_type=\"Featurize-execution\", custom_properties=params)\n",
    "\n",
    "    _ = metawriter.log_dataset(input_ds.train, \"input\")\n",
    "    _ = metawriter.log_dataset(input_ds.test, \"input\")\n",
    "\n",
    "    # Generate train feature matrix\n",
    "    df_train = _get_df(input_ds.train)\n",
    "    train_words = np.array(df_train.text.str.lower().values.astype(\"U\"))\n",
    "\n",
    "    bag_of_words = CountVectorizer(\n",
    "        stop_words=\"english\", max_features=params[\"max_features\"], ngram_range=(1, params[\"ngrams\"])\n",
    "    )\n",
    "\n",
    "    bag_of_words.fit(train_words)\n",
    "    train_words_binary_matrix = bag_of_words.transform(train_words)\n",
    "    tfidf = TfidfTransformer(smooth_idf=False)\n",
    "    tfidf.fit(train_words_binary_matrix)\n",
    "    train_words_tfidf_matrix = tfidf.transform(train_words_binary_matrix)\n",
    "\n",
    "    _save_matrix(df_train, train_words_tfidf_matrix, output_ds.train)\n",
    "\n",
    "    # Generate test feature matrix\n",
    "    df_test = _get_df(input_ds.test)\n",
    "    test_words = np.array(df_test.text.str.lower().values.astype(\"U\"))\n",
    "    test_words_binary_matrix = bag_of_words.transform(test_words)\n",
    "    test_words_tfidf_matrix = tfidf.transform(test_words_binary_matrix)\n",
    "\n",
    "    _save_matrix(df_test, test_words_tfidf_matrix, output_ds.test)\n",
    "\n",
    "    _ = metawriter.log_dataset(output_ds.train, \"output\")\n",
    "    _ = metawriter.log_dataset(output_ds.test, \"output\")\n",
    "\n",
    "def featurize_cli(input_dir: str, output_dir: str) -> None:\n",
    "    featurize(input_dir, output_dir)\n",
    "\n",
    "featurize_cli(\"artifacts/parsed\", \"artifacts/features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1b05bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Note: CMF will check out a new branch in git to commit the metadata files ***\n",
      "*** The checked out branch is mlmd. ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\u280b Checking graph graph\n",
      "Input matrix size (20017, 3002)\n",
      "X matrix size (20017, 3000)\n",
      "Y matrix size (20017,)\n",
      "\\u2839 Checking graph graph\n",
      "\u001b[?25h\r"
     ]
    }
   ],
   "source": [
    "__all__ = ['train']\n",
    "\n",
    "\n",
    "def train(input_dir: str, output_dir: str) -> None:\n",
    "    \"\"\"Train Machine Learning model.\n",
    "    Args:\n",
    "        input_dir: Path to a directory containing train.pkl file.\n",
    "        output_dir: Path to a directory that will contain model.pkl file.\n",
    "\n",
    "    Machine Learning Artifacts:\n",
    "        Input: ${input_dir}/train.pkl\n",
    "        Output: ${output_dir}/model.pkl\n",
    "    \"\"\"\n",
    "    params = yaml.safe_load(open(\"params.yaml\"))[\"train\"]\n",
    "    graph_env = os.getenv(\"NEO4J\", \"False\")\n",
    "    graph = True if graph_env == \"True\" or graph_env == \"TRUE\" else False\n",
    "    metawriter = cmf.Cmf(filename=\"mlmd\", pipeline_name=\"Test-env\", graph=graph)\n",
    "    _ = metawriter.create_context(pipeline_stage=\"Train\")\n",
    "    _ = metawriter.create_execution(execution_type=\"Train-execution\", custom_properties=params)\n",
    "\n",
    "    train_ds = os.path.join(input_dir, \"train.pkl\")\n",
    "    _ = metawriter.log_dataset(train_ds, \"input\")\n",
    "    with open(train_ds, \"rb\") as fd:\n",
    "        matrix = pickle.load(fd)\n",
    "\n",
    "    labels = np.squeeze(matrix[:, 1].toarray())\n",
    "    x = matrix[:, 2:]\n",
    "\n",
    "    sys.stderr.write(\"Input matrix size {}\\n\".format(matrix.shape))\n",
    "    sys.stderr.write(\"X matrix size {}\\n\".format(x.shape))\n",
    "    sys.stderr.write(\"Y matrix size {}\\n\".format(labels.shape))\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=params[\"n_est\"], min_samples_split=params[\"min_split\"], n_jobs=2, random_state=params[\"seed\"]\n",
    "    )\n",
    "    clf.fit(x, labels)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    model_file = os.path.join(output_dir, 'model.pkl')\n",
    "    with open(model_file, \"wb\") as fd:\n",
    "        pickle.dump(clf, fd)\n",
    "\n",
    "    _ = metawriter.log_model(\n",
    "        path=model_file, event=\"output\", model_framework=\"SKlearn\", model_type=\"RandomForestClassifier\",\n",
    "        model_name=\"RandomForestClassifier:default\"\n",
    "    )\n",
    "def train_cli(input_dir: str, output_dir: str) -> None:\n",
    "    train(input_dir, output_dir)\n",
    " \n",
    "train_cli('artifacts/features', 'artifacts/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ba32c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Note: CMF will check out a new branch in git to commit the metadata files ***\n",
      "*** The checked out branch is mlmd. ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\u2819 Checking graph graph\n",
      "\\u280b Checking graph graph\n",
      "\u001b[?25h\r"
     ]
    }
   ],
   "source": [
    "__all__ = ['test']\n",
    "\n",
    "def test(model_dir: str, dataset_dir: str, output_dir: str) -> None:\n",
    "    \"\"\" Test machine learning model.\n",
    "    Args:\n",
    "        model_dir: Path to a directory containing model.pkl file.\n",
    "        dataset_dir: Path to a directory containing test.tsv file.\n",
    "        output_dir: Path to a dataset that will contain several files with performance metrics (scores.json, prc.json\n",
    "            and roc.json).\n",
    "\n",
    "    Machine Learning Artifacts:\n",
    "        Input: ${model_dir}/model.pkl, ${dataset_dir}/test.pkl\n",
    "        Output: ExecutionMetrics\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    Artifacts = collections.namedtuple('Artifacts', ['model', 'dataset', 'scores', 'prc', 'roc'])\n",
    "    artifacts = Artifacts(\n",
    "        model=os.path.join(model_dir, 'model.pkl'),\n",
    "        dataset=os.path.join(dataset_dir, \"test.pkl\"),\n",
    "        scores=os.path.join(output_dir, 'scores.json'),\n",
    "        prc=os.path.join(output_dir, 'prc.json'),\n",
    "        roc=os.path.join(output_dir, 'roc.json')\n",
    "    )\n",
    "    graph_env = os.getenv(\"NEO4J\", \"False\")\n",
    "    graph = True if graph_env == \"True\" or graph_env == \"TRUE\" else False\n",
    "    metawriter = cmf.Cmf(filename=\"mlmd\", pipeline_name=\"Test-env\", graph=graph)\n",
    "    _ = metawriter.create_context(pipeline_stage=\"Evaluate\")\n",
    "    _ = metawriter.create_execution(execution_type=\"Evaluate-execution\")\n",
    "\n",
    "    # TODO: Sergey - how do I know these custom properties here?\n",
    "    metawriter.log_model(\n",
    "        path=artifacts.model, event=\"input\", model_framework=\"sklearn\", model_type=\"RandomForest\",\n",
    "        model_name=\"RandomForest_default\"\n",
    "    )\n",
    "    _ = metawriter.log_dataset(artifacts.dataset, \"input\")\n",
    "\n",
    "    with open(artifacts.model, \"rb\") as fd:\n",
    "        model = pickle.load(fd)\n",
    "    with open(artifacts.dataset, \"rb\") as fd:\n",
    "        dataset = pickle.load(fd)\n",
    "\n",
    "    labels = dataset[:, 1].toarray()\n",
    "    x = dataset[:, 2:]\n",
    "\n",
    "    predictions_by_class = model.predict_proba(x)\n",
    "    predictions = predictions_by_class[:, 1]\n",
    "\n",
    "    precision, recall, prc_thresholds = metrics.precision_recall_curve(labels, predictions)\n",
    "    fpr, tpr, roc_thresholds = metrics.roc_curve(labels, predictions)\n",
    "\n",
    "    avg_prec = metrics.average_precision_score(labels, predictions)\n",
    "    roc_auc = metrics.roc_auc_score(labels, predictions)\n",
    "\n",
    "    # ROC has a drop_intermediate arg that reduces the number of points.\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve.\n",
    "    # PRC lacks this arg, so we manually reduce to 1000 points as a rough estimate.\n",
    "    nth_point = math.ceil(len(prc_thresholds) / 1000)\n",
    "    prc_points = list(zip(precision, recall, prc_thresholds))[::nth_point]\n",
    "    with open(artifacts.prc, \"w\") as fd:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"prc\": [\n",
    "                    {\"precision\": p, \"recall\": r, \"threshold\": t}\n",
    "                    for p, r, t in prc_points\n",
    "                ]\n",
    "            },\n",
    "            fd,\n",
    "            indent=4,\n",
    "        )\n",
    "\n",
    "    with open(artifacts.roc, \"w\") as fd:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"prc\": [\n",
    "                    {\"precision\": p, \"recall\": r, \"threshold\": t}\n",
    "                    for p, r, t in prc_points\n",
    "                ]\n",
    "            },\n",
    "            fd,\n",
    "            indent=4,\n",
    "        )\n",
    "\n",
    "    with open(artifacts.roc, \"w\") as fd:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"roc\": [\n",
    "                    {\"fpr\": fp, \"tpr\": tp, \"threshold\": t}\n",
    "                    for fp, tp, t in zip(fpr, tpr, roc_thresholds)\n",
    "                ]\n",
    "            },\n",
    "            fd,\n",
    "            indent=4,\n",
    "        )\n",
    "\n",
    "    exec_metrics = dict(avg_prec=avg_prec, roc_auc=roc_auc)\n",
    "    with open(artifacts.scores, \"w\") as fd:\n",
    "        json.dump(exec_metrics, fd, indent=4)\n",
    "    _ = metawriter.log_execution_metrics(\"metrics\", exec_metrics)\n",
    "\n",
    "def test_cli(model_dir: str, dataset_dir: str, output_dir: str) -> None:\n",
    "    test(model_dir, dataset_dir, output_dir)\n",
    "\n",
    "test_cli('artifacts/model', 'artifacts/features', 'artifacts/test_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb640a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['query']\n",
    "\n",
    "\n",
    "def _print_executions_in_stage(cmf_query: cmfquery.CmfQuery, stage_name: str) -> None:\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    df: pd.DataFrame = cmf_query.get_all_executions_in_stage(stage_name)\n",
    "    df.drop(columns=['Git_Start_Commit', 'Git_End_Commit'], inplace=True, axis=1)\n",
    "    print(tabulate(df, headers='keys', tablefmt='psql'))\n",
    "\n",
    "\n",
    "def query(mlmd_path: str) -> None:\n",
    "    cmf_query = cmfquery.CmfQuery(mlmd_path)\n",
    "    stages: t.List[str] = cmf_query.get_pipeline_stages(\"Test-env\")\n",
    "    print(stages)\n",
    "\n",
    "    for stage in stages:\n",
    "        _print_executions_in_stage(cmf_query, stage)\n",
    "\n",
    "\n",
    "def query_cli(mlmd_path: str):\n",
    "    query(mlmd_path)\n",
    "\n",
    "query_cli('mlmd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26510d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlmd is successfully pushed.\n"
     ]
    }
   ],
   "source": [
    "# Start cmf-server ui-server to push mlmd \n",
    "_=metadata_push(\"Test-env\",\"./mlmd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43f35337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 files pushed\n"
     ]
    }
   ],
   "source": [
    "#PUSHING ARTIFACTS TO CMF-SERVER\n",
    "_=artifact_push()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e29ce82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e88d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
