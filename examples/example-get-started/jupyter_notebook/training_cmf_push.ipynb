{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c225f8-92e5-460b-8873-d3064dcee272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "import numpy as np\n",
    "from cmflib import cmf\n",
    "from cmflib.cmf import metadata_push, artifact_push\n",
    "import os\n",
    "import io\n",
    "import re \n",
    "import sys\n",
    "import yaml\n",
    "import gzip\n",
    "import pickle\n",
    "import random\n",
    "import typing as t\n",
    "import collections\n",
    "import click\n",
    "import xml.etree.ElementTree\n",
    "from cmflib import cmfquery\n",
    "from cmflib.cli.utils import find_root\n",
    "from cmflib.utils.cmf_config import CmfConfig\n",
    "import requests\n",
    "from sklearn.feature_extraction.text import (CountVectorizer, TfidfTransformer)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import json\n",
    "import math\n",
    "import sklearn.metrics as metrics\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1cffa73-c92f-4d43-b50a-13c5a2be53e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote.local-storage.url=/home/chobey/local-storage\n",
      "core.no_scm=True\n",
      "core.remote=local-storage\n",
      "cmf-server-ip = http://10.93.244.206:8080\n"
     ]
    }
   ],
   "source": [
    "#CHECK WHETHER CMF IS INITIALIZED\n",
    "_=cmf.cmf_init_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f6a1960-75c8-4ff3-bd94-124bae7be509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cmf init.\n",
      "Setting 'local-storage' as a default remote.\n",
      "cmf init complete.\n"
     ]
    }
   ],
   "source": [
    "#INITIALIZING LOCAL REPOSITORY\n",
    "init=cmf.cmf_init(type=\"local\",path=\"/home/chobey/local-storage\",git_remote_url=\"http://github.com\",cmf_server_url=\"http://10.93.244.206:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74ffbb1f-5dc9-4c1f-9a3c-8b9a66edbdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Note: CMF will check out a new branch in git to commit the metadata files ***\n",
      "*** The checked out branch is mlmd. ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\u2819 Checking graph graph\n",
      "\\u2839 Checking graphng stages from the workspace\n",
      "\\u2819 Checking graph graph\n",
      "\u001b[?25h\r"
     ]
    }
   ],
   "source": [
    "__all__ = ['parse']\n",
    "def _process_posts(fd_in: t.IO, fd_out_train: t.IO, fd_out_test: t.IO, target_tag: str, split: int) -> None:\n",
    "    for idx, line in enumerate(fd_in):\n",
    "        try:\n",
    "            fd_out = fd_out_train if random.random() > split else fd_out_test\n",
    "            attr = xml.etree.ElementTree.fromstring(line).attrib\n",
    "\n",
    "            pid = attr.get(\"Id\", \"\")\n",
    "            label = 1 if target_tag in attr.get(\"Tags\", \"\") else 0\n",
    "            title = re.sub(r\"\\s+\", \" \", attr.get(\"Title\", \"\")).strip()\n",
    "            body = re.sub(r\"\\s+\", \" \", attr.get(\"Body\", \"\")).strip()\n",
    "            text = title + \" \" + body\n",
    "\n",
    "            fd_out.write(\"{}\\t{}\\t{}\\n\".format(pid, label, text))\n",
    "        except Exception as ex:\n",
    "            sys.stderr.write(f\"Skipping the broken line {idx}: {ex}\\n\")\n",
    "def parse(input_file: str, output_dir: str) -> None:\n",
    "    \"\"\" Parse input file (input_file) and create train/test files in output_dir directory.\n",
    "    Args:\n",
    "         input_file: Path to a compressed (.gz) XML-lines file (data.xml.gz).\n",
    "         output_dir: Path to a directory that will contain train (train.tsv) and test (test.tsv) files.\n",
    "\n",
    "    Machine Learning Artifacts:\n",
    "        Input: ${input_file}\n",
    "        Output: ${output_dir}/train.tsv, ${output_dir}/test.tsv\n",
    "    \"\"\"\n",
    "    params = yaml.safe_load(open(\"params.yaml\"))[\"parse\"]\n",
    "    random.seed(params[\"seed\"])\n",
    "    graph_env = os.getenv(\"NEO4J\", \"False\")\n",
    "    graph = True if graph_env == \"True\" or graph_env == \"TRUE\" else False\n",
    "    metawriter = cmf.Cmf(filename=\"mlmd\", pipeline_name=\"Test-env\", graph=graph)\n",
    "    _ = metawriter.create_context(pipeline_stage=\"Prepare\", custom_properties={\"user-metadata1\": \"metadata_value\"})\n",
    "    _ = metawriter.create_execution(execution_type=\"Prepare\", custom_properties=params)\n",
    "    _ = metawriter.log_dataset(input_file, \"input\", custom_properties={\"user-metadata1\": \"metadata_value\"})\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    Dataset = collections.namedtuple('Dataset', ['train', 'test'])\n",
    "    output_ds = Dataset(train=os.path.join(output_dir, \"train.tsv\"), test=os.path.join(output_dir, \"test.tsv\"))\n",
    "\n",
    "    with gzip.open(input_file, \"rb\") as fd_in,\\\n",
    "         io.open(output_ds.train, \"w\", encoding=\"utf8\") as fd_out_train,\\\n",
    "         io.open(output_ds.test, \"w\", encoding=\"utf8\") as fd_out_test:\n",
    "        _process_posts(fd_in, fd_out_train, fd_out_test, \"<python>\", params[\"split\"])\n",
    "\n",
    "    _ = metawriter.log_dataset(output_ds.train, \"output\")\n",
    "    _ = metawriter.log_dataset(output_ds.test, \"output\")\n",
    "\n",
    "\n",
    "def parse_cli(input_file: str, output_dir: str) -> None:\n",
    "    parse(input_file, output_dir)\n",
    "\n",
    "parse_cli(\"artifacts/data.xml.gz\", \"artifacts/parsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af2bba2f-f6f8-4026-b028-a9c9ef0f50e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Note: CMF will check out a new branch in git to commit the metadata files ***\n",
      "*** The checked out branch is mlmd. ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\u2839 Checking graphng stages from the workspace\n",
      "\\u2819 Checking graph graph\n",
      "The input data frame artifacts/parsed/train.tsv size is (20017, 3)\n",
      "The output matrix artifacts/features/train.pkl size is (20017, 3002) and data type is float64\n",
      "The input data frame artifacts/parsed/test.tsv size is (4983, 3)\n",
      "The output matrix artifacts/features/test.pkl size is (4983, 3002) and data type is float64\n",
      "\\u2839 Checking graph graph\n",
      "\\u2819 Checking graph graph\n",
      "\u001b[?25h\r"
     ]
    }
   ],
   "source": [
    "__all__ = ['featurize']\n",
    "def _get_df(data: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(\n",
    "        data,\n",
    "        encoding=\"utf-8\",\n",
    "        header=None,\n",
    "        delimiter=\"\\t\",\n",
    "        names=[\"id\", \"label\", \"text\"],\n",
    "    )\n",
    "    sys.stderr.write(f\"The input data frame {data} size is {df.shape}\\n\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def _save_matrix(df: pd.DataFrame, matrix, output: str) -> None:\n",
    "    id_matrix = sparse.csr_matrix(df.id.astype(np.int64)).T\n",
    "    label_matrix = sparse.csr_matrix(df.label.astype(np.int64)).T\n",
    "\n",
    "    result = sparse.hstack([id_matrix, label_matrix, matrix], format=\"csr\")\n",
    "\n",
    "    msg = \"The output matrix {} size is {} and data type is {}\\n\"\n",
    "    sys.stderr.write(msg.format(output, result.shape, result.dtype))\n",
    "\n",
    "    with open(output, \"wb\") as fd:\n",
    "        pickle.dump(result, fd)\n",
    "\n",
    "def featurize(input_dir: str, output_dir: str) -> None:\n",
    "    \"\"\" Create train and test Machine Learning datasets.\n",
    "    Args:\n",
    "        input_dir: Path to a directory containing train.tsv and test.tsv files.\n",
    "        output_dir: Path to a directory that will contain train.pkl and test.pkl files.\n",
    "\n",
    "    Machine Learning Artifacts:\n",
    "        Input: ${input_dir}/train.tsv, ${input_dir}/test.tsv\n",
    "        Output: ${output_dir}/train.pkl, ${output_dir}/test.pkl\n",
    "    \"\"\"\n",
    "    params = yaml.safe_load(open(\"params.yaml\"))[\"featurize\"]\n",
    "    np.set_printoptions(suppress=True)\n",
    "\n",
    "    Dataset = collections.namedtuple('Dataset', ['train', 'test'])\n",
    "    input_ds = Dataset(train=os.path.join(input_dir, \"train.tsv\"), test=os.path.join(input_dir, \"test.tsv\"))\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_ds = Dataset(train=os.path.join(output_dir, \"train.pkl\"), test=os.path.join(output_dir, \"test.pkl\"))\n",
    "    graph_env = os.getenv(\"NEO4J\", \"False\")\n",
    "    graph = True if graph_env == \"True\" or graph_env == \"TRUE\" else False\n",
    "    metawriter = cmf.Cmf(filename=\"mlmd\", pipeline_name=\"Test-env\", graph=graph)\n",
    "\n",
    "    _ = metawriter.create_context(pipeline_stage=\"Featurize\")\n",
    "    _ = metawriter.create_execution(execution_type=\"Featurize-execution\", custom_properties=params)\n",
    "\n",
    "    _ = metawriter.log_dataset(input_ds.train, \"input\")\n",
    "    _ = metawriter.log_dataset(input_ds.test, \"input\")\n",
    "\n",
    "    # Generate train feature matrix\n",
    "    df_train = _get_df(input_ds.train)\n",
    "    train_words = np.array(df_train.text.str.lower().values.astype(\"U\"))\n",
    "\n",
    "    bag_of_words = CountVectorizer(\n",
    "        stop_words=\"english\", max_features=params[\"max_features\"], ngram_range=(1, params[\"ngrams\"])\n",
    "    )\n",
    "\n",
    "    bag_of_words.fit(train_words)\n",
    "    train_words_binary_matrix = bag_of_words.transform(train_words)\n",
    "    tfidf = TfidfTransformer(smooth_idf=False)\n",
    "    tfidf.fit(train_words_binary_matrix)\n",
    "    train_words_tfidf_matrix = tfidf.transform(train_words_binary_matrix)\n",
    "\n",
    "    _save_matrix(df_train, train_words_tfidf_matrix, output_ds.train)\n",
    "\n",
    "    # Generate test feature matrix\n",
    "    df_test = _get_df(input_ds.test)\n",
    "    test_words = np.array(df_test.text.str.lower().values.astype(\"U\"))\n",
    "    test_words_binary_matrix = bag_of_words.transform(test_words)\n",
    "    test_words_tfidf_matrix = tfidf.transform(test_words_binary_matrix)\n",
    "\n",
    "    _save_matrix(df_test, test_words_tfidf_matrix, output_ds.test)\n",
    "\n",
    "    _ = metawriter.log_dataset(output_ds.train, \"output\")\n",
    "    _ = metawriter.log_dataset(output_ds.test, \"output\")\n",
    "\n",
    "def featurize_cli(input_dir: str, output_dir: str) -> None:\n",
    "    featurize(input_dir, output_dir)\n",
    "\n",
    "featurize_cli(\"artifacts/parsed\", \"artifacts/features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91d6a9ec-de73-4d9d-b264-69d025f06de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Note: CMF will check out a new branch in git to commit the metadata files ***\n",
      "*** The checked out branch is mlmd. ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\u2819 Checking graph graph\n",
      "Input matrix size (20017, 3002)\n",
      "X matrix size (20017, 3000)\n",
      "Y matrix size (20017,)\n",
      "\\u2839 Checking graphng stages from the workspace\n",
      "\u001b[?25h\r"
     ]
    }
   ],
   "source": [
    "__all__ = ['train']\n",
    "\n",
    "\n",
    "def train(input_dir: str, output_dir: str) -> None:\n",
    "    \"\"\"Train Machine Learning model.\n",
    "    Args:\n",
    "        input_dir: Path to a directory containing train.pkl file.\n",
    "        output_dir: Path to a directory that will contain model.pkl file.\n",
    "\n",
    "    Machine Learning Artifacts:\n",
    "        Input: ${input_dir}/train.pkl\n",
    "        Output: ${output_dir}/model.pkl\n",
    "    \"\"\"\n",
    "    params = yaml.safe_load(open(\"params.yaml\"))[\"train\"]\n",
    "    graph_env = os.getenv(\"NEO4J\", \"False\")\n",
    "    graph = True if graph_env == \"True\" or graph_env == \"TRUE\" else False\n",
    "    metawriter = cmf.Cmf(filename=\"mlmd\", pipeline_name=\"Test-env\", graph=graph)\n",
    "    _ = metawriter.create_context(pipeline_stage=\"Train\")\n",
    "    _ = metawriter.create_execution(execution_type=\"Train-execution\", custom_properties=params)\n",
    "\n",
    "    train_ds = os.path.join(input_dir, \"train.pkl\")\n",
    "    _ = metawriter.log_dataset(train_ds, \"input\")\n",
    "    with open(train_ds, \"rb\") as fd:\n",
    "        matrix = pickle.load(fd)\n",
    "\n",
    "    labels = np.squeeze(matrix[:, 1].toarray())\n",
    "    x = matrix[:, 2:]\n",
    "\n",
    "    sys.stderr.write(\"Input matrix size {}\\n\".format(matrix.shape))\n",
    "    sys.stderr.write(\"X matrix size {}\\n\".format(x.shape))\n",
    "    sys.stderr.write(\"Y matrix size {}\\n\".format(labels.shape))\n",
    "\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=params[\"n_est\"], min_samples_split=params[\"min_split\"], n_jobs=2, random_state=params[\"seed\"]\n",
    "    )\n",
    "    clf.fit(x, labels)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    model_file = os.path.join(output_dir, 'model.pkl')\n",
    "    with open(model_file, \"wb\") as fd:\n",
    "        pickle.dump(clf, fd)\n",
    "\n",
    "    _ = metawriter.log_model(\n",
    "        path=model_file, event=\"output\", model_framework=\"SKlearn\", model_type=\"RandomForestClassifier\",\n",
    "        model_name=\"RandomForestClassifier:default\"\n",
    "    )\n",
    "def train_cli(input_dir: str, output_dir: str) -> None:\n",
    "    train(input_dir, output_dir)\n",
    " \n",
    "train_cli('artifacts/features', 'artifacts/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8684c761-80fe-4a3e-9115-8e9ef0e3747f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Note: CMF will check out a new branch in git to commit the metadata files ***\n",
      "*** The checked out branch is mlmd. ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\u2838 Checking graphng stages from the workspace\n",
      "\\u2819 Checking graph graph\n",
      "\u001b[?25h\r"
     ]
    }
   ],
   "source": [
    "__all__ = ['test']\n",
    "\n",
    "def test(model_dir: str, dataset_dir: str, output_dir: str) -> None:\n",
    "    \"\"\" Test machine learning model.\n",
    "    Args:\n",
    "        model_dir: Path to a directory containing model.pkl file.\n",
    "        dataset_dir: Path to a directory containing test.tsv file.\n",
    "        output_dir: Path to a dataset that will contain several files with performance metrics (scores.json, prc.json\n",
    "            and roc.json).\n",
    "\n",
    "    Machine Learning Artifacts:\n",
    "        Input: ${model_dir}/model.pkl, ${dataset_dir}/test.pkl\n",
    "        Output: ExecutionMetrics\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    Artifacts = collections.namedtuple('Artifacts', ['model', 'dataset', 'scores', 'prc', 'roc'])\n",
    "    artifacts = Artifacts(\n",
    "        model=os.path.join(model_dir, 'model.pkl'),\n",
    "        dataset=os.path.join(dataset_dir, \"test.pkl\"),\n",
    "        scores=os.path.join(output_dir, 'scores.json'),\n",
    "        prc=os.path.join(output_dir, 'prc.json'),\n",
    "        roc=os.path.join(output_dir, 'roc.json')\n",
    "    )\n",
    "    graph_env = os.getenv(\"NEO4J\", \"False\")\n",
    "    graph = True if graph_env == \"True\" or graph_env == \"TRUE\" else False\n",
    "    metawriter = cmf.Cmf(filename=\"mlmd\", pipeline_name=\"Test-env\", graph=graph)\n",
    "    _ = metawriter.create_context(pipeline_stage=\"Evaluate\")\n",
    "    _ = metawriter.create_execution(execution_type=\"Evaluate-execution\")\n",
    "\n",
    "    # TODO: Sergey - how do I know these custom properties here?\n",
    "    metawriter.log_model(\n",
    "        path=artifacts.model, event=\"input\", model_framework=\"sklearn\", model_type=\"RandomForest\",\n",
    "        model_name=\"RandomForest_default\"\n",
    "    )\n",
    "    _ = metawriter.log_dataset(artifacts.dataset, \"input\")\n",
    "\n",
    "    with open(artifacts.model, \"rb\") as fd:\n",
    "        model = pickle.load(fd)\n",
    "    with open(artifacts.dataset, \"rb\") as fd:\n",
    "        dataset = pickle.load(fd)\n",
    "\n",
    "    labels = dataset[:, 1].toarray()\n",
    "    x = dataset[:, 2:]\n",
    "\n",
    "    predictions_by_class = model.predict_proba(x)\n",
    "    predictions = predictions_by_class[:, 1]\n",
    "\n",
    "    precision, recall, prc_thresholds = metrics.precision_recall_curve(labels, predictions)\n",
    "    fpr, tpr, roc_thresholds = metrics.roc_curve(labels, predictions)\n",
    "\n",
    "    avg_prec = metrics.average_precision_score(labels, predictions)\n",
    "    roc_auc = metrics.roc_auc_score(labels, predictions)\n",
    "\n",
    "    # ROC has a drop_intermediate arg that reduces the number of points.\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve.\n",
    "    # PRC lacks this arg, so we manually reduce to 1000 points as a rough estimate.\n",
    "    nth_point = math.ceil(len(prc_thresholds) / 1000)\n",
    "    prc_points = list(zip(precision, recall, prc_thresholds))[::nth_point]\n",
    "    with open(artifacts.prc, \"w\") as fd:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"prc\": [\n",
    "                    {\"precision\": p, \"recall\": r, \"threshold\": t}\n",
    "                    for p, r, t in prc_points\n",
    "                ]\n",
    "            },\n",
    "            fd,\n",
    "            indent=4,\n",
    "        )\n",
    "\n",
    "    with open(artifacts.roc, \"w\") as fd:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"prc\": [\n",
    "                    {\"precision\": p, \"recall\": r, \"threshold\": t}\n",
    "                    for p, r, t in prc_points\n",
    "                ]\n",
    "            },\n",
    "            fd,\n",
    "            indent=4,\n",
    "        )\n",
    "\n",
    "    with open(artifacts.roc, \"w\") as fd:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"roc\": [\n",
    "                    {\"fpr\": fp, \"tpr\": tp, \"threshold\": t}\n",
    "                    for fp, tp, t in zip(fpr, tpr, roc_thresholds)\n",
    "                ]\n",
    "            },\n",
    "            fd,\n",
    "            indent=4,\n",
    "        )\n",
    "\n",
    "    exec_metrics = dict(avg_prec=avg_prec, roc_auc=roc_auc)\n",
    "    with open(artifacts.scores, \"w\") as fd:\n",
    "        json.dump(exec_metrics, fd, indent=4)\n",
    "    _ = metawriter.log_execution_metrics(\"metrics\", exec_metrics)\n",
    "\n",
    "def test_cli(model_dir: str, dataset_dir: str, output_dir: str) -> None:\n",
    "    test(model_dir, dataset_dir, output_dir)\n",
    "\n",
    "test_cli('artifacts/model', 'artifacts/features', 'artifacts/test_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cca77467-23f2-49be-b04d-816a450be9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Test-env/Prepare', 'Test-env/Featurize', 'Test-env/Train', 'Test-env/Evaluate']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+----+--------------+------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+--------------------------------------------+-----------------+---------------+------+--------+----------+---------+\n",
      "|    |   Context_ID | Context_Type     | Execution                                                                                                                                                                           | Execution_uuid                       | Git_Repo                                   | Pipeline_Type   |   Pipeline_id |   id | name   |     seed |   split |\n",
      "|----+--------------+------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+--------------------------------------------+-----------------+---------------+------+--------+----------+---------|\n",
      "|  0 |            2 | Test-env/Prepare | ['/home/chobey/jupyter/jenv/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/home/chobey/.local/share/jupyter/runtime/kernel-89586477-2c55-47e3-b9c4-b5615b617992.json'] | 602a33d0-4e24-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   29 |        | 20170428 |     0.2 |\n",
      "|  1 |            2 | Test-env/Prepare | ['/home/chobey/jupyter/jenv/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/home/chobey/.local/share/jupyter/runtime/kernel-58051966-6034-4648-bff7-44df2859a4ad.json'] | e2aaee3e-4e02-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   24 |        | 20170428 |     0.2 |\n",
      "|  2 |            2 | Test-env/Prepare | ['/home/chobey/jupyter/jenv/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/home/chobey/.local/share/jupyter/runtime/kernel-58051966-6034-4648-bff7-44df2859a4ad.json'] | d7a54b7e-4e02-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   23 |        | 20170428 |     0.2 |\n",
      "|  3 |            2 | Test-env/Prepare | ['/home/chobey/jupyter/jenv/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/home/chobey/.local/share/jupyter/runtime/kernel-16a2d065-cff5-4fbd-badc-0a68b7b5fe72.json'] | d5cedb64-4dec-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   19 |        | 20170428 |     0.2 |\n",
      "|  4 |            2 | Test-env/Prepare | ['/home/chobey/jupyter/jenv/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/home/chobey/.local/share/jupyter/runtime/kernel-16a2d065-cff5-4fbd-badc-0a68b7b5fe72.json'] | 953a48f6-4dea-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   15 |        | 20170428 |     0.2 |\n",
      "|  5 |            2 | Test-env/Prepare | ['/home/chobey/jupyter/jenv/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/home/chobey/.local/share/jupyter/runtime/kernel-16a2d065-cff5-4fbd-badc-0a68b7b5fe72.json'] | 6c1f05f6-4dea-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   14 |        | 20170428 |     0.2 |\n",
      "|  6 |            2 | Test-env/Prepare | ['src/parse.py', 'artifacts/data.xml.gz', 'artifacts/parsed']                                                                                                                       | 031b992c-4d75-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   10 |        | 20170428 |     0.2 |\n",
      "|  7 |            2 | Test-env/Prepare | ['src/parse.py', 'artifacts/data.xml.gz', 'artifacts/parsed']                                                                                                                       | 45981aec-4d74-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |    6 |        | 20170428 |     0.2 |\n",
      "|  8 |            2 | Test-env/Prepare | ['src/parse.py', 'artifacts/data.xml.gz', 'artifacts/parsed']                                                                                                                       | e719a842-4d40-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |    5 |        | 20170428 |     0.2 |\n",
      "|  9 |            2 | Test-env/Prepare | ['src/parse.py', 'artifacts/data.xml.gz', 'artifacts/parsed']                                                                                                                       | 349901aa-4d3f-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |    1 |        | 20170428 |     0.2 |\n",
      "+----+--------------+------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+--------------------------------------------+-----------------+---------------+------+--------+----------+---------+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+----+--------------+--------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+--------------------------------------------+-----------------+---------------+------+----------------+--------+----------+\n",
      "|    |   Context_ID | Context_Type       | Execution                                                                                                                                                                           | Execution_uuid                       | Git_Repo                                   | Pipeline_Type   |   Pipeline_id |   id |   max_features | name   |   ngrams |\n",
      "|----+--------------+--------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+--------------------------------------------+-----------------+---------------+------+----------------+--------+----------|\n",
      "|  0 |            3 | Test-env/Featurize | ['/home/chobey/jupyter/jenv/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/home/chobey/.local/share/jupyter/runtime/kernel-89586477-2c55-47e3-b9c4-b5615b617992.json'] | 69258804-4e24-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   30 |           3000 |        |        2 |\n",
      "|  1 |            3 | Test-env/Featurize | ['/home/chobey/jupyter/jenv/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/home/chobey/.local/share/jupyter/runtime/kernel-58051966-6034-4648-bff7-44df2859a4ad.json'] | 00b0f72a-4e03-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   25 |           3000 |        |        2 |\n",
      "|  2 |            3 | Test-env/Featurize | ['/home/chobey/jupyter/jenv/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/home/chobey/.local/share/jupyter/runtime/kernel-16a2d065-cff5-4fbd-badc-0a68b7b5fe72.json'] | de687302-4dec-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   20 |           3000 |        |        2 |\n",
      "|  3 |            3 | Test-env/Featurize | ['/home/chobey/jupyter/jenv/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/home/chobey/.local/share/jupyter/runtime/kernel-16a2d065-cff5-4fbd-badc-0a68b7b5fe72.json'] | 56c0a704-4deb-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   16 |           3000 |        |        2 |\n",
      "|  4 |            3 | Test-env/Featurize | ['src/featurize.py', 'artifacts/parsed', 'artifacts/features']                                                                                                                      | 0d315f14-4d75-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   11 |           3000 |        |        2 |\n",
      "|  5 |            3 | Test-env/Featurize | ['src/featurize.py', 'artifacts/parsed', 'artifacts/features']                                                                                                                      | 4ef9b96a-4d74-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |    7 |           3000 |        |        2 |\n",
      "|  6 |            3 | Test-env/Featurize | ['src/featurize.py', 'artifacts/parsed', 'artifacts/features']                                                                                                                      | 3dd05aa2-4d3f-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |    2 |           3000 |        |        2 |\n",
      "+----+--------------+--------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+--------------------------------------------+-----------------+---------------+------+----------------+--------+----------+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+----+--------------+----------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+--------------------------------------------+-----------------+---------------+------+-------------+---------+--------+----------+\n",
      "|    |   Context_ID | Context_Type   | Execution                                                                                                                                                                           | Execution_uuid                       | Git_Repo                                   | Pipeline_Type   |   Pipeline_id |   id |   min_split |   n_est | name   |     seed |\n",
      "|----+--------------+----------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+--------------------------------------------+-----------------+---------------+------+-------------+---------+--------+----------|\n",
      "|  0 |            4 | Test-env/Train | ['/home/chobey/jupyter/jenv/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/home/chobey/.local/share/jupyter/runtime/kernel-89586477-2c55-47e3-b9c4-b5615b617992.json'] | 8348568a-4e24-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   31 |          64 |     100 |        | 20170428 |\n",
      "|  1 |            4 | Test-env/Train | ['/home/chobey/jupyter/jenv/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/home/chobey/.local/share/jupyter/runtime/kernel-58051966-6034-4648-bff7-44df2859a4ad.json'] | 3623e840-4e03-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   27 |          64 |     100 |        | 20170428 |\n",
      "|  2 |            4 | Test-env/Train | ['/home/chobey/jupyter/jenv/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/home/chobey/.local/share/jupyter/runtime/kernel-58051966-6034-4648-bff7-44df2859a4ad.json'] | 1f37c8cc-4e03-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   26 |          64 |     100 |        | 20170428 |\n",
      "|  3 |            4 | Test-env/Train | ['/home/chobey/jupyter/jenv/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/home/chobey/.local/share/jupyter/runtime/kernel-16a2d065-cff5-4fbd-badc-0a68b7b5fe72.json'] | f817d784-4dec-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   21 |          64 |     100 |        | 20170428 |\n",
      "|  4 |            4 | Test-env/Train | ['/home/chobey/jupyter/jenv/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/home/chobey/.local/share/jupyter/runtime/kernel-16a2d065-cff5-4fbd-badc-0a68b7b5fe72.json'] | e65286ee-4deb-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   17 |          64 |     100 |        | 20170428 |\n",
      "|  5 |            4 | Test-env/Train | ['src/train.py', 'artifacts/features', 'artifacts/model']                                                                                                                           | 26dada9e-4d75-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   12 |          64 |     100 |        | 20170428 |\n",
      "|  6 |            4 | Test-env/Train | ['src/train.py', 'artifacts/features', 'artifacts/model']                                                                                                                           | 6810b03e-4d74-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |    8 |          64 |     100 |        | 20170428 |\n",
      "|  7 |            4 | Test-env/Train | ['src/train.py', 'artifacts/features', 'artifacts/model']                                                                                                                           | 583219e4-4d3f-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |    3 |          64 |     100 |        | 20170428 |\n",
      "+----+--------------+----------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+--------------------------------------------+-----------------+---------------+------+-------------+---------+--------+----------+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+----+--------------+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+--------------------------------------------+-----------------+---------------+------+--------+\n",
      "|    |   Context_ID | Context_Type      | Execution                                                                                                                                                                           | Execution_uuid                       | Git_Repo                                   | Pipeline_Type   |   Pipeline_id |   id | name   |\n",
      "|----+--------------+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+--------------------------------------------+-----------------+---------------+------+--------|\n",
      "|  0 |            5 | Test-env/Evaluate | ['/home/chobey/jupyter/jenv/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/home/chobey/.local/share/jupyter/runtime/kernel-89586477-2c55-47e3-b9c4-b5615b617992.json'] | 8bde8ecc-4e24-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   32 |        |\n",
      "|  1 |            5 | Test-env/Evaluate | ['/home/chobey/jupyter/jenv/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/home/chobey/.local/share/jupyter/runtime/kernel-58051966-6034-4648-bff7-44df2859a4ad.json'] | 474b0b76-4e03-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   28 |        |\n",
      "|  2 |            5 | Test-env/Evaluate | ['/home/chobey/jupyter/jenv/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/home/chobey/.local/share/jupyter/runtime/kernel-16a2d065-cff5-4fbd-badc-0a68b7b5fe72.json'] | 00bb4754-4ded-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   22 |        |\n",
      "|  3 |            5 | Test-env/Evaluate | ['/home/chobey/jupyter/jenv/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/home/chobey/.local/share/jupyter/runtime/kernel-16a2d065-cff5-4fbd-badc-0a68b7b5fe72.json'] | 6a764a5a-4dec-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   18 |        |\n",
      "|  4 |            5 | Test-env/Evaluate | ['src/test.py', 'artifacts/model', 'artifacts/features', 'artifacts/test_results']                                                                                                  | 309db1dc-4d75-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |   13 |        |\n",
      "|  5 |            5 | Test-env/Evaluate | ['src/test.py', 'artifacts/model', 'artifacts/features', 'artifacts/test_results']                                                                                                  | 70b1f54a-4d74-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |    9 |        |\n",
      "|  6 |            5 | Test-env/Evaluate | ['src/test.py', 'artifacts/model', 'artifacts/features', 'artifacts/test_results']                                                                                                  | 60f960d2-4d3f-11ee-82bb-8f3f07423144 | https://github.com/varkha-d-sharma/cmf.git | Test-env        |             1 |    4 |        |\n",
      "+----+--------------+-------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------+--------------------------------------------+-----------------+---------------+------+--------+\n"
     ]
    }
   ],
   "source": [
    "__all__ = ['query']\n",
    "\n",
    "\n",
    "def _print_executions_in_stage(cmf_query: cmfquery.CmfQuery, stage_name: str) -> None:\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    df: pd.DataFrame = cmf_query.get_all_executions_in_stage(stage_name)\n",
    "    df.drop(columns=['Git_Start_Commit', 'Git_End_Commit'], inplace=True, axis=1)\n",
    "    print(tabulate(df, headers='keys', tablefmt='psql'))\n",
    "\n",
    "\n",
    "def query(mlmd_path: str) -> None:\n",
    "    cmf_query = cmfquery.CmfQuery(mlmd_path)\n",
    "    stages: t.List[str] = cmf_query.get_pipeline_stages(\"Test-env\")\n",
    "    print(stages)\n",
    "\n",
    "    for stage in stages:\n",
    "        _print_executions_in_stage(cmf_query, stage)\n",
    "\n",
    "\n",
    "def query_cli(mlmd_path: str):\n",
    "    query(mlmd_path)\n",
    "\n",
    "query_cli('mlmd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b13d2ccb-3c97-49bb-9b06-a8aa2cbb414f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlmd is successfully pushed.\n"
     ]
    }
   ],
   "source": [
    "# Start cmf-server ui-server to push mlmd \n",
    "_=metadata_push(\"Test-env\",\"./mlmd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9bf37a4-8487-4e19-aa76-0bfd8a5bd24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 files pushed\n"
     ]
    }
   ],
   "source": [
    "#PUSHING ARTIFACTS TO CMF-SERVER\n",
    "_=artifact_push()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c239b8-638a-45e1-91a2-0366882976f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d94884-41c1-46a8-a02b-adb7322b8253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
